{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 34, "column": 0}, "map": {"version":3,"sources":["file:///Users/jake/Documents/Demos/vercel-ai-sdk/lib/openai.ts"],"sourcesContent":["import { openai } from \"@ai-sdk/openai\";\nexport { openai };\n\n"],"names":[],"mappings":";AAAA"}},
    {"offset": {"line": 54, "column": 0}, "map": {"version":3,"sources":["file:///Users/jake/Documents/Demos/vercel-ai-sdk/lib/sub-agent.ts"],"sourcesContent":["import {\n  generateText,\n  streamText,\n  generateObject,\n  streamObject,\n  wrapLanguageModel,\n} from \"ai\";\nimport { openai } from \"@/lib/openai\";\nimport { traceable } from \"langsmith/traceable\";\nimport { wrapAISDK } from \"langsmith/experimental/vercel\";\nimport { Client } from \"langsmith\";\n\n// LangSmith client for tracing\nconst langsmithClient = new Client();\nconst researchReplicas = [{ projectName: \"vercel-researcher\" }];\n\n// Wrap AI SDK for automatic tracing\nconst wrappedAISDK = wrapAISDK(\n  {\n    wrapLanguageModel,\n    generateText,\n    streamText,\n    streamObject,\n    generateObject,\n  },\n  {\n    project_name: \"vercel-ai-agent-demo\",\n    replicas: researchReplicas,\n  }\n);\n\n/**\n * Sub-agent that specializes in research and analysis tasks\n * This agent is called as a tool from the main agent\n * Traces are sent to both the main project and the 'vercel-researcher' project via replicas\n */\nexport const researchAgent = traceable(\n  async (query: string): Promise<string> => {\n    const result = await wrappedAISDK.generateText({\n      model: openai(\"gpt-4o-mini\"),\n      system: `You are a specialized research assistant. Your job is to provide detailed,\n      well-researched answers to questions. Focus on accuracy, clarity, and depth.\n      Keep responses concise but informative.`,\n      prompt: query,\n    });\n\n    return result.text;\n  },\n  { \n    name: \"research_agent\", \n    run_type: \"llm\",\n    client: langsmithClient,\n    replicas: researchReplicas\n  }\n);\n"],"names":[],"mappings":";;;;AAAA;AAOA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;;;;;;AAEA,+BAA+B;AAC/B,MAAM,kBAAkB,IAAI,sJAAM;AAClC,MAAM,mBAAmB;IAAC;QAAE,aAAa;IAAoB;CAAE;AAE/D,oCAAoC;AACpC,MAAM,eAAe,IAAA,mLAAS,EAC5B;IACE,mBAAA,2KAAiB;IACjB,cAAA,sKAAY;IACZ,YAAA,oKAAU;IACV,cAAA,sKAAY;IACZ,gBAAA,wKAAc;AAChB,GACA;IACE,cAAc;IACd,UAAU;AACZ;AAQK,MAAM,gBAAgB,IAAA,6JAAS,EACpC,OAAO;IACL,MAAM,SAAS,MAAM,aAAa,YAAY,CAAC;QAC7C,OAAO,IAAA,mKAAM,EAAC;QACd,QAAQ,CAAC;;6CAE8B,CAAC;QACxC,QAAQ;IACV;IAEA,OAAO,OAAO,IAAI;AACpB,GACA;IACE,MAAM;IACN,UAAU;IACV,QAAQ;IACR,UAAU;AACZ"}},
    {"offset": {"line": 109, "column": 0}, "map": {"version":3,"sources":["file:///Users/jake/Documents/Demos/vercel-ai-sdk/lib/tools.ts"],"sourcesContent":["import { z } from \"zod\";\nimport { researchAgent } from \"./sub-agent\";\nimport { withRunTree } from \"langsmith/traceable\";\n\ntype RunTreeContext = Parameters<typeof withRunTree>[0];\n\nconst runAsIsolatedTrace = async <T>(fn: () => Promise<T>) => {\n  // Passing `undefined` drops the parent ALS context so the wrapped traceable function\n  // creates a new root run (allowing us to use custom replicas for this tool only).\n  return withRunTree(undefined as unknown as RunTreeContext, fn);\n};\n\nconst addNumbersSchema = z.object({\n  a: z.number(),\n  b: z.number(),\n});\n\nconst researchQuerySchema = z.object({\n  query: z.string().describe(\"The research question or topic to investigate\"),\n});\n\nexport const tools = {\n  addNumbers: {\n    description: \"Add two numbers together\",\n    inputSchema: addNumbersSchema,\n    execute: async ({ a, b }: { a: number; b: number }) => {\n      return { result: a + b };\n    },\n  },\n  askResearchAgent: {\n    description: \"Delegate complex research or analysis questions to a specialized research agent. Use this when you need detailed information or in-depth analysis.\",\n    inputSchema: researchQuerySchema,\n    execute: async ({ query }: { query: string }) => {\n      const answer = await runAsIsolatedTrace(() => researchAgent(query));\n      return { answer };\n    },\n  },\n};\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AAAA;;;;AAIA,MAAM,qBAAqB,OAAU;IACnC,qFAAqF;IACrF,kFAAkF;IAClF,OAAO,IAAA,+JAAW,EAAC,WAAwC;AAC7D;AAEA,MAAM,mBAAmB,oLAAC,CAAC,MAAM,CAAC;IAChC,GAAG,oLAAC,CAAC,MAAM;IACX,GAAG,oLAAC,CAAC,MAAM;AACb;AAEA,MAAM,sBAAsB,oLAAC,CAAC,MAAM,CAAC;IACnC,OAAO,oLAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC7B;AAEO,MAAM,QAAQ;IACnB,YAAY;QACV,aAAa;QACb,aAAa;QACb,SAAS,OAAO,EAAE,CAAC,EAAE,CAAC,EAA4B;YAChD,OAAO;gBAAE,QAAQ,IAAI;YAAE;QACzB;IACF;IACA,kBAAkB;QAChB,aAAa;QACb,aAAa;QACb,SAAS,OAAO,EAAE,KAAK,EAAqB;YAC1C,MAAM,SAAS,MAAM,mBAAmB,IAAM,IAAA,sIAAa,EAAC;YAC5D,OAAO;gBAAE;YAAO;QAClB;IACF;AACF"}},
    {"offset": {"line": 157, "column": 0}, "map": {"version":3,"sources":["file:///Users/jake/Documents/Demos/vercel-ai-sdk/app/api/agent/route.ts"],"sourcesContent":["import {\n  generateText,\n  streamText,\n  generateObject,\n  streamObject,\n  wrapLanguageModel,\n} from \"ai\";\nimport { openai } from \"@/lib/openai\";\nimport { tools } from \"@/lib/tools\";\nimport { traceable } from \"langsmith/traceable\";\nimport { wrapAISDK } from \"langsmith/experimental/vercel\";\nimport { Client } from \"langsmith\";\n\n// Using Node.js runtime for LangSmith Client compatibility\nexport const runtime = \"nodejs\";\n\nconst langsmithClient = new Client();\n\n// Wrap AI SDK for automatic tracing\nconst wrappedAISDK = wrapAISDK(\n  {\n    wrapLanguageModel,\n    generateText,\n    streamText,\n    streamObject,\n    generateObject,\n  },\n  {\n    project_name: \"vercel-ai-agent-demo\",\n  }\n);\n\nconst handleAgentRequest = traceable(\n  async (messages: any[]) => {\n    const result = await wrappedAISDK.generateText({\n      model: openai(\"gpt-4o\"),\n      messages,\n      tools,\n    });\n\n    return {\n      text: result.text,\n      toolCalls: result.toolCalls,\n      toolResults: result.toolResults,\n      finishReason: result.finishReason,\n    };\n  },\n  {\n    name: \"main_agent\",\n    run_type: \"chain\",\n    client: langsmithClient,\n  }\n);\n\nexport async function POST(req: Request) {\n  const { messages } = await req.json();\n  const result = await handleAgentRequest(messages);\n\n  // Ensure traces are flushed before response\n  await langsmithClient.awaitPendingTraceBatches();\n\n  return Response.json(result);\n}\n"],"names":[],"mappings":";;;;;;AAAA;AAOA;AAAA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;;;;;;;AAGO,MAAM,UAAU;AAEvB,MAAM,kBAAkB,IAAI,sJAAM;AAElC,oCAAoC;AACpC,MAAM,eAAe,IAAA,mLAAS,EAC5B;IACE,mBAAA,2KAAiB;IACjB,cAAA,sKAAY;IACZ,YAAA,oKAAU;IACV,cAAA,sKAAY;IACZ,gBAAA,wKAAc;AAChB,GACA;IACE,cAAc;AAChB;AAGF,MAAM,qBAAqB,IAAA,6JAAS,EAClC,OAAO;IACL,MAAM,SAAS,MAAM,aAAa,YAAY,CAAC;QAC7C,OAAO,IAAA,mKAAM,EAAC;QACd;QACA,OAAA,uHAAK;IACP;IAEA,OAAO;QACL,MAAM,OAAO,IAAI;QACjB,WAAW,OAAO,SAAS;QAC3B,aAAa,OAAO,WAAW;QAC/B,cAAc,OAAO,YAAY;IACnC;AACF,GACA;IACE,MAAM;IACN,UAAU;IACV,QAAQ;AACV;AAGK,eAAe,KAAK,GAAY;IACrC,MAAM,EAAE,QAAQ,EAAE,GAAG,MAAM,IAAI,IAAI;IACnC,MAAM,SAAS,MAAM,mBAAmB;IAExC,4CAA4C;IAC5C,MAAM,gBAAgB,wBAAwB;IAE9C,OAAO,SAAS,IAAI,CAAC;AACvB"}}]
}